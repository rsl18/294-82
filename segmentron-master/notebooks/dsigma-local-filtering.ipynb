{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Blur by Local Filtering\n",
    "\n",
    "For exact adaptive blurring, instantiate a Gaussian for every kernel window, making a blur for each window.\n",
    "This local filtering is carried out by matrix multiplication with the `im2col` matrix of the input and the stacked blur kernels.\n",
    "\n",
    "This is not efficient in time or memory: every blur kernel is fit into the same max size and sampled separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap\n",
    "\n",
    "# work from project root for local imports\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# root here refers to the segmentron-master folder\n",
    "root_dir = Path(subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).strip().decode(\"utf-8\"))\n",
    "root_dir = root_dir / \"segmentron-master\"\n",
    "os.chdir(root_dir)\n",
    "sys.path.append(str(root_dir))\n",
    "\n",
    "from sigma.blur import blur2d_full, blur2d_local_full, blur2d_local_sphere\n",
    "from sigma.blur import gauss2d_full, sigma2logchol, logchol2sigma\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a Gaussian blur through the log-Cholesky parameterization, and then convolve with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_sphere = torch.diag(torch.Tensor([2., 2.]))\n",
    "sigma_diag = torch.diag(torch.Tensor([2., 4.]))\n",
    "sigma_full = torch.Tensor([[1., 1.],\n",
    "                           [1., 4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chol_filter_ = gauss2d_full(sigma2logchol(sigma_full))\n",
    "kh, kw = chol_filter_.size()[-2:]\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title('log-Cholesky filter')\n",
    "plt.imshow(chol_filter_.squeeze().numpy())\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review convolution by matrix multiplication:\n",
    "\n",
    "1. unroll the image by extracting patches, flattening, and stacking into the `im2col` matrix.\n",
    "2. consider the filter weights as a out x in x height x width matrix, and flatten the trailing spatial dimensions\n",
    "3. convolve by matrix multiplication of the image matrix and weight matrix\n",
    "4. roll the output matrix back into an image by restoring the spatial dimensions.\n",
    "\n",
    "Why convolve this way? It takes advantage of highly-tuned matrix multiplication routines, and we can generalize to local *non-convolutional* filtering by adding a further dimension to the weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = torch.randn(2, 1, 64, 64)\n",
    "in_mat = F.unfold(im, kernel_size=(kh, kw), padding=(kh // 2, kw // 2))\n",
    "weight_mat = chol_filter_.view(1, -1, 1).repeat(2, 1, 1)\n",
    "out_mat = torch.bmm(in_mat.permute(0, 2, 1), weight_mat)\n",
    "out = out_mat.view(im.size())\n",
    "\n",
    "print(f\"image matrix size {tuple(weight_mat.size())} weight matrix size {tuple(weight_mat.size())}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(im[1].squeeze().numpy())\n",
    "plt.figure()\n",
    "plt.imshow(out[1].squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate many sigmas at once through the log-Cholesky parameterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.randn(9, 3) * 0.5\n",
    "blurs = gauss2d_full(params)\n",
    "plt.figure()\n",
    "for i, b in enumerate(blurs, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    plt.imshow(b.squeeze().numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make an exact, adaptive blur we go from convolutional filtering to local filtering.\n",
    "In local filtering, the filter varies with the indices, so that different locations have different kernels.\n",
    "Note this requires instantiating a kernel for each blur, and stacking them all into a matrix, so computation and memory scales with the *maximum* kernel size, which is clearly not ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = torch.randn(2, 3, 32, 32)\n",
    "# instantiate a blur for each position\n",
    "batch_size, channel_size, spatial_size = im.size(0), im.size(1), im.size(2) * im.size(3)\n",
    "params = torch.randn(batch_size * spatial_size, 3) * 0.2\n",
    "blurs = gauss2d_full(params)\n",
    "kh, kw = blurs.size()[-2:]\n",
    "\n",
    "# form input matrix by unrolling image, pulling out channel, \n",
    "# then stacking everything but the kernel into the batch \n",
    "in_mat = F.unfold(im, kernel_size=(kh, kw), padding=(kh // 2, kw // 2))\n",
    "in_mat = in_mat.view(batch_size, channel_size, kh * kw, spatial_size)\n",
    "in_mat = in_mat.permute(0, 1, 3, 2).contiguous().view(im.numel(), 1, kh * kw)\n",
    "# form weight matrix by pulling out batch and flattening kernel,\n",
    "# repeating across channels, and then absorbing channels into the batch.\n",
    "weight_mat = blurs.view(batch_size, 1, spatial_size, -1)\n",
    "weight_mat = weight_mat.repeat(1, channel_size, 1, 1).view(-1, kh * kw, 1)\n",
    "\n",
    "# matmul + reshape takes the product of each input-filter pair\n",
    "# and restores the spatial dimensions\n",
    "out_mat = torch.matmul(in_mat, weight_mat)\n",
    "out = out_mat.view(im.size())\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Image Input')\n",
    "plt.imshow(im[1, 2].squeeze().numpy())\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Locally Blurred Output')\n",
    "plt.imshow(out[1, 2].squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Experiment: Optimize $\\Sigma$ to Recover Local Full Covariance Blurs in 2D\n",
    "\n",
    "To illustrate adaptive blurring via optimizing sigma with a toy problem, let's recover the covariances of local blurs from smoothed data in 2D.\n",
    "\n",
    "1. Generate a random 2D signal and smooth it with reference sigmas, in different quadrants.\n",
    "2. Instantiate our filters with zero initialization of the covariance parameters, which is equivalent to identity covariance.\n",
    "3. Learn sigmas by gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 1, 32, 32)\n",
    "quarter_spatial = (x.size(2) * x.size(3)) // 4\n",
    "sphere_params = sigma2logchol(sigma_sphere)\n",
    "diag_params = sigma2logchol(sigma_diag)\n",
    "full_params = sigma2logchol(sigma_full)\n",
    "true_cov = torch.cat((sphere_params.repeat(quarter_spatial, 1),\n",
    "                      diag_params.repeat(quarter_spatial, 1),\n",
    "                      full_params.repeat(quarter_spatial, 1),\n",
    "                      torch.randn(quarter_spatial, 3) * 0.2), dim=0)\n",
    "xf = blur2d_local_full(x, true_cov, std_devs=2).detach()\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('signal')\n",
    "plt.imshow(x.squeeze().numpy())\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('smoothed')\n",
    "plt.imshow(xf.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_recovery(xf, xf_hat, iter_):\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    plt.title(\"Recovery iter. {}\".format(iter_))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(xf.squeeze().detach().numpy())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(xf_hat.squeeze().detach().numpy())\n",
    "    \n",
    "cov = torch.nn.Parameter(torch.zeros(x.numel() // x.size(1), 3))\n",
    "opt = torch.optim.Adamax([cov], lr=0.1)\n",
    "\n",
    "max_iter = 100\n",
    "for iter_ in range(max_iter):\n",
    "    xf_hat = blur2d_local_full(x, cov, std_devs=2)\n",
    "    diff = xf_hat - xf\n",
    "    loss = (diff**2).mean()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    if iter_ % 10 == 0:\n",
    "        print('loss ', loss.item())\n",
    "    if iter_ in (0, max_iter // 4, max_iter // 2):\n",
    "        plot_recovery(xf, xf_hat, iter_)\n",
    "plot_recovery(xf, xf_hat, iter_ + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Recovered - Reference Squared Error\")\n",
    "plt.imshow(((xf - xf_hat)**2).detach().squeeze().numpy())\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Covariance Parameter MSE')\n",
    "plt.imshow((true_cov - cov).pow(2.).mean(-1).view(x.size()[2:]).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simplify by restricting the true covariance to spherical, and recovering it by spherical local blur and full local blur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter_spatial = (x.size(2) * x.size(3)) // 4\n",
    "true_scales = torch.cat((torch.full((quarter_spatial,), -1.),\n",
    "                         torch.full((quarter_spatial,), -0.5),\n",
    "                         torch.full((quarter_spatial,), 0.),\n",
    "                         torch.full((quarter_spatial,), 0.5)), dim=0)\n",
    "xf = blur2d_local_sphere(x, true_scales.exp(), std_devs=2).detach()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('signal')\n",
    "plt.imshow(x.squeeze().numpy())\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('smoothed')\n",
    "plt.imshow(xf.squeeze().numpy())\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_recovery(xf, xf_hat, iter_):\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    plt.title(\"Recovery iter. {}\".format(iter_))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(xf.squeeze().detach().numpy())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(xf_hat.squeeze().detach().numpy())\n",
    "    \n",
    "scales = torch.nn.Parameter(torch.zeros(x.numel() // x.size(1)))\n",
    "opt = torch.optim.Adamax([scales], lr=0.1)\n",
    "\n",
    "max_iter = 100\n",
    "for iter_ in range(max_iter):\n",
    "    xf_hat = blur2d_local_sphere(x, scales.exp(), std_devs=2)\n",
    "    diff = xf_hat - xf\n",
    "    loss = (diff**2).mean()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    if iter_ % 10 == 0:\n",
    "        print('loss ', loss.item())\n",
    "    if iter_ in (0, max_iter // 4, max_iter // 2):\n",
    "        plot_recovery(xf, xf_hat, iter_)\n",
    "plot_recovery(xf, xf_hat, iter_ + 1)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title(\"Recovered Spherical - Smoothed\")\n",
    "plt.imshow(((xf - xf_hat)**2).detach().squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_recovery(xf, xf_hat, iter_):\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    plt.title(\"Recovery iter. {}\".format(iter_))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(xf.squeeze().detach().numpy())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(xf_hat.squeeze().detach().numpy())\n",
    "    \n",
    "cov = torch.nn.Parameter(torch.zeros(x.numel() // x.size(1), 3))\n",
    "opt = torch.optim.Adamax([cov], lr=0.1)\n",
    "\n",
    "max_iter = 100\n",
    "for iter_ in range(max_iter):\n",
    "    xf_hat = blur2d_local_full(x, cov, std_devs=2)\n",
    "    diff = xf_hat - xf\n",
    "    loss = (diff**2).mean()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    if iter_ % 10 == 0:\n",
    "        print('loss ', loss.item())\n",
    "    if iter_ in (0, max_iter // 4, max_iter // 2):\n",
    "        plot_recovery(xf, xf_hat, iter_)\n",
    "plot_recovery(xf, xf_hat, iter_ + 1)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title(\"Recovered Full - Smoothed\")\n",
    "plt.imshow(((xf - xf_hat)**2).detach().squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the learned covariances, first by looking at the mean at a given y coord.\n",
    "From left-to-right is top-to-bottom, and the covariance grows with y, as expected given the true blur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cov = cov.view(32, 32, 3)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, y_ in enumerate([0, 8, 16, 31], 1):\n",
    "    f = gauss2d_full(im_cov[y_, :].mean(0), std_devs=2)\n",
    "    plt.subplot(1, 4, i)\n",
    "    plt.title(f\"y = {y_}, ks = {tuple(f.size())}\")\n",
    "    plt.imshow(f.detach().squeeze().numpy())\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's examine individual covariances more closely.\n",
    "There's a perhaps surprising amount of diversity, indicating that more data or regularization could help.\n",
    "Granted, this is a tiny toy experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cov = cov.view(32, 32, 3)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, y_ in enumerate([0, 8, 16, 31], 1):\n",
    "    for j, x_ in enumerate([0, 8, 16, 31], 1):\n",
    "        f = gauss2d_full(im_cov[y_, x_], std_devs=2)\n",
    "        plt.subplot(4, 4, (i-1)*4 + j)\n",
    "        plt.title(f\"y, x = {y_}, {x_} ks = {tuple(f.size())}\")\n",
    "        plt.imshow(f.detach().squeeze().numpy())\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
