{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compound Receptive Fields\n",
    "\n",
    "From the elementary receptive fields of blurs and convolutions, we can make compound receptive fields by their combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# work from project root for local imports\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# root here refers to the segmentron-master folder\n",
    "root_dir = Path(subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).strip().decode(\"utf-8\"))\n",
    "root_dir = root_dir / \"segmentron-master\"\n",
    "os.chdir(root_dir)\n",
    "sys.path.append(str(root_dir))\n",
    "\n",
    "from sigma.blur import gauss2d_sphere\n",
    "from sigma.blur import blur2d_sphere\n",
    "from sigma.blur import dog1d, dog2d\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-scale by Cascade Smoothing\n",
    "\n",
    "**Cascade smoothing** is the property of Gaussians that the variance of the composition of Gaussians is the sum of their variances.\n",
    "That is, for $G_\\circ = G_1 \\circ G_2$ the variance obeys $\\sigma_\\circ^2 = \\sigma_1^2 + \\sigma_2^2$.\n",
    "\n",
    "For multi-scale processing, we could filter in parallel with blurs for each scale or we could harness cascade smoothing to filter in sequence with smaller blurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center-surround has little(r) and bigg(er) blurs\n",
    "lil_sigma = torch.tensor(3.)\n",
    "big_sigma = torch.tensor(5.)\n",
    "# cascade smoothing calculates the large blur from the center blur\n",
    "# by solving for the variance that sums to the large variance\n",
    "cascade_sigma = (big_sigma.pow(2) - lil_sigma.pow(2)).pow(0.5)\n",
    "\n",
    "print(\"sigmas: \", lil_sigma, big_sigma, cascade_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 1, 128, 128)\n",
    "\n",
    "x_lil = blur2d_sphere(x, lil_sigma)\n",
    "x_big = blur2d_sphere(x, big_sigma)\n",
    "x_cascade = blur2d_sphere(x_lil, cascade_sigma)\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title('signal')\n",
    "plt.imshow(x.detach().squeeze().numpy())\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title('small')\n",
    "plt.imshow(x_lil.detach().squeeze().numpy())\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title('large')\n",
    "plt.axis('off')\n",
    "plt.imshow(x_big.detach().squeeze().numpy())\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title('cascade')\n",
    "plt.imshow(x_cascade.detach().squeeze().numpy())\n",
    "plt.axis('off')\n",
    "\n",
    "cascade_mse = (x_big - x_cascade).pow(2).mean().item()\n",
    "print(f\"difference between direct and cascade is {cascade_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time the sequential cascade and the parallel center-surround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x_lil = blur2d_sphere(x, lil_sigma)\n",
    "x_cascade = blur2d_sphere(x_lil, cascade_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x_lil = blur2d_sphere(x, lil_sigma)\n",
    "x_big = blur2d_sphere(x, big_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh well, there isn't much difference, at least at these dimensions.\n",
    "It matters more if the dimensions are larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center-Surround\n",
    "\n",
    "**Center-surround** have a smaller center enclosed in a larger surround, and because the center and surround responses have different signs, these receptive fields are sensitive to contrast.\n",
    "They are objects of study in their own right in visual neuroscience and practical for signal processing as **difference of Gaussians (DoG)** for bandpass filtering.\n",
    "DoG filtering subtracts a large blur from a small blur, preserving the frequencies in between that range.\n",
    "\n",
    "A contrastive receptive field made by the difference of local and dilated filters is used to good effect in [Context Contrasted Feature and Gated Multi-scale Aggregation for Scene Segmentation. Ding et al. CVPR'18](http://openaccess.thecvf.com/content_cvpr_2018/papers/Ding_Context_Contrasted_Feature_CVPR_2018_paper.pdf).\n",
    "\n",
    "Let's inspect DoG filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impulse = torch.zeros(1, 1, 19)\n",
    "impulse.view(-1)[impulse.numel() // 2] = 1.\n",
    "f_dog = dog1d(impulse, lil_sigma, big_sigma)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"Difference of Gaussians (DoG)\")\n",
    "plt.plot(f_dog.detach().squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in 2D this time.\n",
    "First let's calculate the DoG kernel ourselves, then compare with the impulse response from our module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine kernel size to cover +/- 2 sigma s.t. >95% of density is included\n",
    "half_size = int(max(1, torch.ceil(big_sigma * 2.)))\n",
    "# always make odd kernel to keep coordinates centered\n",
    "kernel_size = half_size*2 + 1\n",
    "# calculate unnormalized density then normalize\n",
    "coord = torch.linspace(-half_size, half_size, steps=kernel_size)\n",
    "lil_filter = torch.exp(-coord**2 / (2*lil_sigma**2))\n",
    "big_filter = torch.exp(-coord**2 / (2*big_sigma**2))\n",
    "# 2D is product of 1D b.c. this is isotropic\n",
    "lil_filter = lil_filter.view(-1, 1) @ lil_filter.view(1, -1)\n",
    "big_filter = big_filter.view(-1, 1) @ big_filter.view(1, -1)\n",
    "# DoG is the difference of the smaller and large blur\n",
    "dog_filter = lil_filter / lil_filter.sum() - big_filter / big_filter.sum()\n",
    "dog_filter -= dog_filter.mean()\n",
    "\n",
    "impulse = torch.zeros(1, 1, 21, 21)\n",
    "impulse.view(-1)[impulse.numel() // 2] = 1.\n",
    "\n",
    "dog_response = dog2d(impulse, lil_sigma, big_sigma)\n",
    "dog_response -= dog_response.mean()\n",
    "\n",
    "dog_diff = (dog_filter - dog_response).pow(2).mean() \n",
    "\n",
    "print(f\"Difference in DoG kernels {dog_diff}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"DoG (manual)\")\n",
    "plt.imshow(dog_filter.detach().squeeze().numpy())\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"dog2d (function)\")\n",
    "plt.imshow(dog_response.detach().squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the DoG filter output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show filtered signals\n",
    "x_center = blur2d_sphere(x, lil_sigma)\n",
    "x_surround = blur2d_sphere(x, big_sigma)\n",
    "x_dog = dog2d(x, lil_sigma, big_sigma)\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title('signal')\n",
    "plt.imshow(x.detach().squeeze().numpy())\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title('center')\n",
    "plt.imshow(x_center.detach().squeeze().numpy())\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title('surround')\n",
    "plt.axis('off')\n",
    "plt.imshow(x_surround.detach().squeeze().numpy())\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title('DoG')\n",
    "plt.imshow(x_dog.detach().squeeze().numpy())\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "h4d_env",
   "language": "python",
   "name": "h4d_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
