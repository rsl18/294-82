{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Blur by Mixing Min/Max\n",
    "\n",
    "For a recklessly approximate approach to adaptivity, mix minimum and maximum blurs by weighting with a convex combination.\n",
    "The weights can be set across location to locally adapt scale.\n",
    "\n",
    "This approximation is *rough*.\n",
    "The result for $\\frac{1}{2}\\sigma_{\\text{min}} + \\frac{1}{2}\\sigma_{\\text{max}}$ is not the same as blurring with $\\sigma_{\\frac{\\text{min} + \\text{max}}{2}}$, and in particular the high frequencies of the minimum blur come through.\n",
    "\n",
    "However, solving for the mixing weights is able to improve the fit from the average of the min/max extremes, so it is doing something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# work from the project root\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# root here refers to the segmentron-master folder\n",
    "root_dir = Path(subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).strip().decode(\"utf-8\"))\n",
    "root_dir = root_dir / \"segmentron-master\"\n",
    "os.chdir(root_dir)\n",
    "sys.path.append(str(root_dir))\n",
    "\n",
    "from sigma.blur import blur1d, blur2d_sphere\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Experiment: Optimize Mixing to Recover Blur Kernel in 2D\n",
    "\n",
    "To illustrate the optimization of mixing scales with a toy problem, let's recover the size of the Gaussian blur when the blur is (1) convolutional and (2) local.\n",
    "\n",
    "1. Generate a random 2D signal and smooth it with a reference sigma.\n",
    "2. Instantiate our scale steering mixing with a minimum blur, maximum blur, and equal weighting.\n",
    "3. Learn the weighting by gradient descent.\n",
    "\n",
    "Note that the min/max blurs are themselves differentiable blurs, so the bounds could be tuned.\n",
    "\n",
    "First we inspect the approximation when the true blur is the average of the min/max blur.\n",
    "Of course when the true blur is the min or max, it is exact, but the intermediate blurs are (very) approximate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur2d_mix(x, min_sigma, max_sigma, mix=0.5):\n",
    "    x_min = blur2d_sphere(x, min_sigma)\n",
    "    x_max = blur2d_sphere(x, max_sigma)\n",
    "    return mix * x_min + (1 - mix) * x_max\n",
    "    \n",
    "x = torch.randn(1, 1, 64, 64)\n",
    "true_sigma = torch.tensor(3.)\n",
    "xf = blur2d_sphere(x, true_sigma).detach()\n",
    "xm = blur2d_mix(x, torch.tensor(1.0), torch.tensor(5.0), torch.tensor(0.5))\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('signal')\n",
    "plt.imshow(x.squeeze().numpy())\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('true')\n",
    "plt.imshow(xf.squeeze().numpy())\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('mixed')\n",
    "plt.imshow(xm.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's attempt to recover an intermediate scale by mixing.\n",
    "It isn't too close, but it's better than the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_recovery(xf, xf_hat, iter_):\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    plt.title(\"Recovery iter. {}\".format(iter_))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(xf.squeeze().detach().numpy())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(xf_hat.squeeze().detach().numpy())\n",
    "    \n",
    "true_sigma = torch.tensor(3.)\n",
    "\n",
    "min_sigma = torch.tensor(3.)\n",
    "max_sigma = torch.tensor(9.)\n",
    "\n",
    "xf = blur2d_sphere(x, true_sigma, std_devs=2)\n",
    "\n",
    "mix = torch.nn.Parameter(torch.tensor(0.0))\n",
    "opt = torch.optim.Adamax([mix], lr=0.1)\n",
    "\n",
    "max_iter = 1000\n",
    "for iter_ in range(max_iter):\n",
    "    xf_hat = blur2d_mix(x, min_sigma, max_sigma, torch.sigmoid(mix))\n",
    "    diff = xf_hat - xf\n",
    "    loss = (diff**2).mean()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    if iter_ % 100 == 0:\n",
    "        print('loss ', loss.item())\n",
    "    if iter_ in (0, 4, 16):\n",
    "        plot_recovery(xf, xf_hat, iter_)\n",
    "plot_recovery(xf, xf_hat, iter_ + 1)\n",
    "\n",
    "weight = torch.sigmoid(mix)\n",
    "approx_sigma = weight * min_sigma + (-weight + 1.) * max_sigma\n",
    "\n",
    "print('\\ntrue sigma {:0.2f} recovered sigma {:0.2f}'.format(true_sigma.item(), approx_sigma.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last blur was still global.\n",
    "Let's experiment with mixing to recover a local blur: the left half of the reference is sharper and the right half is blurrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_recovery(xf, xf_hat, iter_):\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    plt.title(\"Recovery iter. {}\".format(iter_))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(xf.squeeze().detach().numpy())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(xf_hat.squeeze().detach().numpy())\n",
    "    \n",
    "true_lil_sigma = torch.tensor(4.)\n",
    "true_big_sigma = torch.tensor(7.)\n",
    "\n",
    "min_sigma = torch.tensor(3.)\n",
    "max_sigma = torch.tensor(9.)\n",
    "\n",
    "mix = torch.cat((torch.ones(x.size(-1) // 2), torch.zeros(x.size(-1) // 2)))\n",
    "xf = blur2d_mix(x, true_lil_sigma, true_big_sigma, mix)\n",
    "\n",
    "mix = torch.nn.Parameter(torch.zeros_like(x))\n",
    "opt = torch.optim.Adamax([mix], lr=0.1)\n",
    "\n",
    "max_iter = 1000\n",
    "for iter_ in range(max_iter):\n",
    "    xf_hat = blur2d_mix(x, min_sigma, max_sigma, torch.sigmoid(mix))\n",
    "    diff = xf_hat - xf\n",
    "    loss = (diff**2).mean()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    if iter_ % 100 == 0:\n",
    "        print('loss ', loss.item())\n",
    "    if iter_ in (0, 4, 16):\n",
    "        plot_recovery(xf, xf_hat, iter_)\n",
    "plot_recovery(xf, xf_hat, iter_ + 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
